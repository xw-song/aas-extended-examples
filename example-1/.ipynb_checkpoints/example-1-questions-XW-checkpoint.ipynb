{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flipping coins with Professor Mittens\n",
    "\n",
    "In this lab we will look at the binomial distribution, central limit theorem, and analyse two data sets collected by [Professor Mittens](https://en.wikipedia.org/wiki/Mittens_(cat)) helping him interrogate the bais in the results of coin flips. Some of the questions are open-ended by design. Partial solutions will be distributed at the end of the session. The imports below are used in the provided solutions, consider these suggestions, not constraints. The answers use `altair` but you can use any plotting library you are comfortable with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import altair as alt\n",
    "from typing import List, Any, Tuple\n",
    "from functools import reduce\n",
    "from itertools import repeat\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation of the binomial distribution\n",
    "\n",
    "Bernoulli and binomial random variables are the typical way to represent the outcome of coin flips. Below we consider estimates of the probability of heads based on a known number of successes in a given number of trials and also a confidence interval (CI) for this based on the Wald method will be given.\n",
    "\n",
    "Let $X$ be a binomial random variable (RV) which results from the number of heads when a coin is flipped $n$ times and the probability of coming up heads is $p$. For the time being we will assume that $n$ is know. The expected value of $X$ is $np$. So a simple way to estimate $p$ is to divide the number of heads, $X$, by the number of flips, $n$. This gives the estimate \n",
    "\n",
    "$$\n",
    "\\hat{p} = X / n.\n",
    "$$\n",
    "\n",
    "It turns out that this is a very sensible thing to do. The resulting estimate is called the maximum likelihood estimate (MLE) of $p$. It is also the result that one obtains via [the method of moments](https://en.wikipedia.org/wiki/Method_of_moments_(statistics)).\n",
    "\n",
    "Given an estimator though, we want to know how confident we are in the estimate it produces. Here we will use the Wald method to get the $95\\%$ CI. It is a very simple method but is acceptable when we have a fair bit of data. The estimated standard error of $\\hat{p}$ is $\\sqrt{\\hat{p}(1-\\hat{p})/n}$, so the Wald CI is given by\n",
    "\n",
    "$$\n",
    "\\hat{p} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n",
    "$$\n",
    "\n",
    "where $z$ is the appropriate quantile of the standard normal distribution. In the case of a $95\\%$ distribution this is just $1.96$.\n",
    "\n",
    "This is stated on the [wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution#Estimation_of_parameters) but there is also a reasonably clear description in [All of Statistics](https://link.springer.com/book/10.1007/978-0-387-21736-9) which you can get via SOLO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 part I\n",
    "\n",
    "Professor Mittens is not very familiar with the binomial distribution and wants you to justify the estimator used above. Convince yourself that the estimate given above, $X/n$, is a sensible choice. Prove that it is either the MLE or the method of moments estimator for $p$. State the limitations on the estimator we are using for the CI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XW$\\hat{p}^2$\n",
    "\n",
    "\n",
    "Given $n$ trials we know the $X\\sim Bin(n,p)$\n",
    "\n",
    "We know that the expected value of the Binomial random variable is $n p$ i.e. $$\n",
    "\n",
    "Mom says estimate $p$ by equating \n",
    "\n",
    "$\\hat{X} = p n$ Solve for $p$ gives us the estimate that $p = $\\bar{X}/n\n",
    "\n",
    "MOM\n",
    "If you get all the moments that define a distribution, the \n",
    "(we know p and we are trying to calculate the average from p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 part II\n",
    "\n",
    "Implement a function called `wald_estimate_and_ci` which takes two arguments: `num_trials` which is $n$ in the description above, and `num_success` which is $X$ above. The function should return `(p_hat,(wald_lower,wald_upper))` where `p_hat` is $\\hat{p}$ and `wald_x` are the limits on the $95\\%$ CI using the Wald method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5, (0.19009678930349883, 0.8099032106965012))\n"
     ]
    }
   ],
   "source": [
    "#p hat is the probability of heads in each trial!\n",
    "#p hat is essentially number of successes divided by number of trials\n",
    "#z is 1.96 - you can get that via the quantile function\n",
    "#in the CLT, the sampling distribution will look normal, the wald estimate is derived from that - the square root here is the standard deviation of the sample mean distribution (which is normal under the CLT assumption), the content of the CLT is that as your sample size gets large the sampling distribution will look normal\n",
    "\n",
    "# def wald_estimate_and_ci(num_trials, num_success):\n",
    "#     p_hat = num_success / num_trials\n",
    "#     z = 1.96\n",
    "#     delta = z * math.sqrt(p_hat * (1 - p_hat) / num_trials)\n",
    "#     wald_lower = (p_hat - delta)\n",
    "#     wald_upper = (p_hat + delta)\n",
    "#     return p_hat,(wald_lower,wald_upper)\n",
    "\n",
    "CI = Tuple[float,float]\n",
    "EstimateAndCI = Tuple[float,CI]\n",
    "\n",
    "def wald_estimate_and_ci(num_trials: int, num_success: int) -> EstimateAndCI:\n",
    "    p_hat = num_success / num_trials\n",
    "    z = 1.96\n",
    "    delta = z * math.sqrt(p_hat * (1 - p_hat) / num_trials)\n",
    "    return (p_hat,(p_hat - delta, p_hat + delta))\n",
    "\n",
    "print(wald_estimate_and_ci(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 part I\n",
    "\n",
    "Look up how to simulate a random variable from a binomial distribution (it tells you [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom) if you want to use `scipy`). Then simulate a binomial random variable with $n=100$ and $p=0.6$. Then use the value and the `wald_estimate_and_ci` function to see how well you can estimate $p$. Write a couple of sentences to explain this.\n",
    "\n",
    "### Exercise 2 part II\n",
    "\n",
    "Repeat the process about 100000 times and see what proportion of the CIs capture the true value of $p$. Is it what you expect? Write a couple of sentences to explain what you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "60034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6e-06, (-9.182049170780606e-06, 2.1182049170780608e-05))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from scipy.stats import binom\n",
    "import numpy as np\n",
    "\n",
    "# Ex2 Part1\n",
    "n, p = 100, 0.6\n",
    "value = np.random.binomial(n,p)\n",
    "print(value)\n",
    "\n",
    "wald_estimate_and_ci(n,p)\n",
    "\n",
    "# Ex2 Part2\n",
    "n, p = 100000, 0.6\n",
    "value = np.random.binomial(n,p)\n",
    "print(value)\n",
    "\n",
    "wald_estimate_and_ci(n,p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 part III\n",
    "\n",
    "Are credible intervals and confidence intervals the same thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central limit theorem\n",
    "\n",
    "The central limit theorem tells us about the limiting distribution of the sample mean for distribution for an IID sample with a finite variance. It underpins many results in statistics and is important for reasoning about stochastic processes.\n",
    "\n",
    "### Exercise 3 part I\n",
    "\n",
    "Professor Mittens *really* likes to sound fancy and use the name of important theorems. Write down a statement of the law of large numbers. Write down a statement of the central limit theorem. Make sure you understand what each of them tells you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 part II\n",
    "\n",
    "To see that the distribution of the sample mean converges to a normal distribution we will do a simulation study and compare the results with a Q-Q plot to see if it looks normally distributed. This will also demonstrate how to construct a Q-Q plot from first principles, not that you really want to do that. Carry out the following steps:\n",
    "\n",
    "1. Write down the distribution of the sample mean given an IID sample of exponential random variables\n",
    "2. Generate 100 sample means each based on a sample of 100 exponential random variables\n",
    "3. Make a histogram and a Q-Q plot to see if the sample means do appear to follow a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45264.83050950369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Refer to Page 38 of Notes\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sample_size = 100 # number of exponential random variables\n",
    "num_replicates = 1000\n",
    "\n",
    "np.random.exponential(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental results: flipping coins in series\n",
    "\n",
    "Professor Mittens asked 15 of his students to each take turns flipping a coin 30 times and recording how many heads they got. He has a sneaking suspicion that some of the students did not actually do this properly, that they just wrote down some garbage and went to lunch early. We will help Mittens work out whether the coin that was used was fair, i.e. has an equal chance of showing heads or tails.\n",
    "\n",
    "### Exercise 3 part I\n",
    "\n",
    "Read the data in `experiement1.csv` into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exp1 = pd.read_csv('experiment1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 part II\n",
    "\n",
    "Compute the point estimate and CI using the function you wrote above. Write a sentence explaining whether you think the coin is a _fair_ coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      outcome  name\n",
       "name               \n",
       "0          14     0\n",
       "1           8     1\n",
       "2          15     2\n",
       "3          12     3\n",
       "4          11     4\n",
       "5          13     5\n",
       "6          17     6\n",
       "7          11     7\n",
       "8          15     8\n",
       "9           9     9\n",
       "10         13    10\n",
       "11         13    11\n",
       "12         14    12\n",
       "13         30    13\n",
       "14         30    14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b7be1d440aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_flips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwald_estimate_and_ci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_people\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_flips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-b58cad699595>\u001b[0m in \u001b[0;36mwald_estimate_and_ci\u001b[0;34m(num_trials, num_success)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mp_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_success\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.96\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_hat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_hat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "head_counts = exp1.drop(columns=\"flip_number\").groupby(\"name\").sum()\n",
    "head_counts[\"name\"] = head_counts.index.copy()\n",
    "display(head_counts)\n",
    "\n",
    "total_heads = int(head_counts[\"outcome\"].sum())\n",
    "num_people = int(head_counts[\"name\"].unique().size)\n",
    "num_flips = int(exp1[\"name\"].value_counts().unique())\n",
    "\n",
    "wald_estimate_and_ci(total_heads, num_people * num_flips)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 part III\n",
    "\n",
    "Generate a histogram of the number of heads from each student. As an extension, include the binomial distribution supported by your estimate that is most amenable to large value outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 part I\n",
    "\n",
    "It looks like there might be a couple of strange points in this dataset as Mittens suspected. Using the upper bound on $p$ calculate the probability of someone getting all heads. Write a couple of sentences explaining whether you think it is reasonable to remove those data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 part II\n",
    "\n",
    "Remove the outliers and repeat the process of plotting the data and estimating the parameters and CI. Once you have done this, plot the distribution of the estimated binomial distribution on top of the histogram. Write a couple of sentences explaining what you think about the coin now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental results: flipping coins in parallel\n",
    "\n",
    "After the success of his first experiment, Mittens was lauded as a statistical wizard. The royal mint has become interested and is providing additional funds to obtain an additional 49 coins and repeat the experiment to gather more data about the fascinating topic of coin bias. Now he gives each of 50 students a coin each and asks them to flip the coin 30 times and record the results. We will help Mittens work out whether the coins are fair.\n",
    "\n",
    "### Excercise 5 part I\n",
    "\n",
    "Do we need to change anything about how we analyse this data? If so, why, if not, why not? **Hint:** there are good arguments that can be given for each answer. Once you have answered one way, try to answer the other way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 part II\n",
    "\n",
    "Using the data in `experiment2.csv` explore the data set using the methodology devised above and write a couple of sentences to explain what you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4126666666666667, (0.38775215028289883, 0.43758118305043453))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2 = pd.read_csv('experiment2.csv')\n",
    "\n",
    "head_counts = exp2.drop(columns=\"flip_number\").groupby(\"name\").sum()\n",
    "head_counts[\"name\"] = head_counts.index.copy()\n",
    "\n",
    "total_heads = int(head_counts[\"outcome\"].sum())\n",
    "num_people = int(head_counts[\"name\"].unique().size)\n",
    "num_flips = int(exp2[\"name\"].value_counts().unique())\n",
    "\n",
    "wald_estimate_and_ci(num_people * num_flips, total_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 part III\n",
    "\n",
    "Visualise the number of heads each student got and compare the variance in this to what is predicted by theory. Revise your answer to part I of this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'histplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3940f52d7caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'histplot'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 part IV (Extension)\n",
    "\n",
    "Consider how you might analyse this data. Over the following weeks you will learn a couple of approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue\n",
    "\n",
    "Professor Mittens' work was published in a top tier journal and he was lauded as a statistical wizard. Rumour has it he will soon be elected to the British Acadmey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
